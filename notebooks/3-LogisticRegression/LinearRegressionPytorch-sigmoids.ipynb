{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26e8a83",
   "metadata": {},
   "source": [
    "## Linear Regression- with sigmoid\n",
    "    \n",
    "(based on a tutorial by Python Engineer in Youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47b2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np            #for data transformation\n",
    "from sklearn import datasets  #to load binary classification dataset\n",
    "from sklearn.preprocessing import StandardScaler #to scale our features\n",
    "from sklearn.model_selection import train_test_split #to separate training and testing data\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6f803",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "    0. prepare the data\n",
    "    1. setup a model\n",
    "    2. loss and optimizer\n",
    "    3. training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7f106",
   "metadata": {},
   "source": [
    "## Step 0 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "692a2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f79502c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#scale the features\n",
    "sc = StandardScaler()   #make our features to have 0 mean and unit variance!!! always recommended to do \n",
    "                        #when we're dealing with logistic regression\n",
    "    \n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "#convert to torch tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "#reshape Y tensor\n",
    "y_train = y_train.view(y_train.shape[0], 1) # y has only one row, but we want to have a column vector\n",
    "                                            # so we want to put each value in one row\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4e41d",
   "metadata": {},
   "source": [
    "## Step 1 - Model\n",
    "\n",
    "Here, the model is f = wx + b, and at the end a sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1855c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=30, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1) #one class label at the end\n",
    "        \n",
    "    def forward(self, x):  #don't change this function's name :)\n",
    "        y_predicted = torch.sigmoid(self.linear(x)) #value between 0 and 1\n",
    "        return y_predicted\n",
    "\n",
    "model = LogisticRegression(n_features)  # so 30 input and 1 output\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090b74c",
   "metadata": {},
   "source": [
    "## Step 2 - Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e4ae979",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()      #binary Cross Entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c3475",
   "metadata": {},
   "source": [
    "## Step 3 - Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1be95dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss =  0.5379\n",
      "epoch:20, loss =  0.4411\n",
      "epoch:30, loss =  0.3811\n",
      "epoch:40, loss =  0.3403\n",
      "epoch:50, loss =  0.3107\n",
      "epoch:60, loss =  0.2880\n",
      "epoch:70, loss =  0.2699\n",
      "epoch:80, loss =  0.2551\n",
      "epoch:90, loss =  0.2427\n",
      "epoch:100, loss =  0.2321\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    #forwardpass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    #loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    #backward\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    \n",
    "    #empty the gradients because the backward function above adds all the gradient to grad attribute\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch:{epoch+1}, loss = {loss.item(): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c707186",
   "metadata": {},
   "source": [
    "## Evaluate the model \n",
    "\n",
    "This step should not be part of the computational graph. => with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0144455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is = 92.11\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicated = model(X_test)\n",
    "    y_predicted_class = y_predicated.round()  # as the output of sigmoid is between 0 and 1,\n",
    "                                            # if it's larger than 0.5 is class 1 ow class 0.\n",
    "\n",
    "    # to calculate accuracy we want to know about all data with equal y_pred_class and y_test\n",
    "    # devided by the number of samples => y_test.shape[0]\n",
    "    \n",
    "    acc = y_predicted_class.eq(y_test).sum()/ float(y_test.shape[0])\n",
    "    \n",
    "    print(f'The accuracy is = {acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d999bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
